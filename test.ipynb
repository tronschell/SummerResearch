{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import os\r\n",
    "import json\r\n",
    "from company_name import *\r\n",
    "from pymongo import MongoClient\r\n",
    "import re\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "try:\r\n",
    "    cluster = MongoClient(\"mongodb+srv://tron-schell:Aurf7046@covidresearch0.d3ctd.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\", serverSelectionTimeoutMS=5000)\r\n",
    "    database = cluster['CovidResearch']\r\n",
    "    collection = database['entire_doc_employee']\r\n",
    "    print(\"Connected successfully!!!\")\r\n",
    "except:\r\n",
    "    print(\"Could not connect to MongoDB\")\r\n",
    "\r\n",
    "\r\n",
    "#db.entire_doc_employee('CIK', {$or: [{'Secondary Word':\"laid off\"}, {'Secondary Word':\"layoffs\"}, {'Secondary Word':\"layoff\", {'Secondary Word':\"furlough\"}, {'Secondary Word':\"furloughs\"}})\r\n",
    "\r\n",
    "\r\n",
    "documents = []\r\n",
    "#count_not_found = 0\r\n",
    "primary_wordlist = ['COVID-19']\r\n",
    "secondary_wordlist = ['salary reduction', 'reducing', 'benefits']\r\n",
    "\r\n",
    "not_found = []\r\n",
    "foundcount = 1\r\n",
    "\r\n",
    "found_lst = []\r\n",
    "\r\n",
    "# This finds all of the files with the .txt extension and adds the name of the file to the list called \"documents\"\r\n",
    "for root, dirs, files, in os.walk('sec-edgar-filings'):\r\n",
    "    for file in files:\r\n",
    "        if file.endswith('.txt'):\r\n",
    "            documents.append(os.path.join(root, file))\r\n",
    "\r\n",
    "\r\n",
    "for doc in range(int(len(documents))):\r\n",
    "    path = str(documents[doc])\r\n",
    "\r\n",
    "\r\n",
    "    with open(path, 'r') as f:\r\n",
    "\r\n",
    "        raw_10k = f.read()\r\n",
    "\r\n",
    "        #Try to run this, if something happens, go to the next document but also increment the count for the amount of things not found\r\n",
    "\r\n",
    "        print('Checking document', documents[doc])\r\n",
    "        print('Checking number', doc, 'out of', len(documents))\r\n",
    "        #Add all of the paragraphs to the item_1a_paragrpahs list\r\n",
    "        doc_content = BeautifulSoup(raw_10k, 'lxml')\r\n",
    "\r\n",
    "        #This block of code finds the tag with the most amount of information inside of it and makes it the primary tag for finding things\r\n",
    "        #This was made instead of having different tables/collections for different tags\r\n",
    "        p_doc_paragraphs = doc_content.findAll('p')\r\n",
    "        span_doc_paragraphs = doc_content.findAll('span')\r\n",
    "        font_doc_paragraphs = doc_content.findAll('font')\r\n",
    "\r\n",
    "        doc_start_pattern = re.compile(r'<DOCUMENT>')\r\n",
    "        doc_end_pattern = re.compile(r'</DOCUMENT>')\r\n",
    "\r\n",
    "        type_pattern = re.compile(r'<TYPE>[^\\n]+')\r\n",
    "\r\n",
    "        doc_start_is = [x.end() for x in doc_start_pattern.finditer(raw_10k)]\r\n",
    "        doc_end_is = [x.start() for x in doc_end_pattern.finditer(raw_10k)]\r\n",
    "\r\n",
    "        doc_types = [x[len('<TYPE>'):] for x in type_pattern.findall(raw_10k)]\r\n",
    "\r\n",
    "        document = {}\r\n",
    "\r\n",
    "        # Create a loop to go through each section type and save only the 10-K section in the dictionary\r\n",
    "        for doc_type, doc_start, doc_end in zip(doc_types, doc_start_is, doc_end_is):\r\n",
    "            if doc_type == '10-K':\r\n",
    "                document[doc_type] = raw_10k[doc_start:doc_end]\r\n",
    "\r\n",
    "        regex = re.compile(r'((ITEM)|(Item)|(item))\\s?(\\&nbsp;)?(\\d\\w?)[.:-]\\s?(\\&nbsp;)?(\\&nbsp;)?(\\&nbsp;)?(\\&nbsp;)?\\s?(\\w){0,4}', flags =re.S|re.M|re.I)\r\n",
    "\r\n",
    "        # Use finditer to math the regex\r\n",
    "        #matches = regex.finditer(document['10-K'])\r\n",
    "\r\n",
    "\r\n",
    "        matches = regex.finditer(document['10-K'])\r\n",
    "        # Create the dataframe\r\n",
    "        test_df = pd.DataFrame([(x.group(), x.start(), x.end()) for x in matches])\r\n",
    "\r\n",
    "        test_df.columns = ['item', 'start', 'end']\r\n",
    "        test_df['item'] = test_df.item.str.lower()\r\n",
    "\r\n",
    "        test_df.replace('&#160;',' ',regex=True,inplace=True)\r\n",
    "        test_df.replace('&nbsp;',' ',regex=True,inplace=True)\r\n",
    "        test_df.replace(' ','',regex=True,inplace=True)\r\n",
    "        test_df.replace('\\.','',regex=True,inplace=True)\r\n",
    "        test_df.replace('\\n','',regex=True,inplace=True)\r\n",
    "        test_df.replace('>','',regex=True,inplace=True)\r\n",
    "\r\n",
    "        pos_dat = test_df.sort_values('start', ascending=True).drop_duplicates(subset=['item'], keep='last')\r\n",
    "\r\n",
    "        pos_dat.set_index('item', inplace=True)\r\n",
    "        #print(test_df)\r\n",
    "        print(pos_dat)\r\n",
    "        #print('item 1a: ', test_df[test_df['item'].str.contains(r'item1a')])\r\n",
    "\r\n",
    "        if (len(p_doc_paragraphs) > len(span_doc_paragraphs)) and (len(p_doc_paragraphs) > len(font_doc_paragraphs)):\r\n",
    "            print('using p doc paragraphs')\r\n",
    "            doc_paragraphs = p_doc_paragraphs\r\n",
    "            tags = 'p'\r\n",
    "        elif (len(span_doc_paragraphs) > len(p_doc_paragraphs)) and (len(span_doc_paragraphs) > len(font_doc_paragraphs)):\r\n",
    "            print('using span paragraphs')\r\n",
    "            doc_paragraphs = span_doc_paragraphs\r\n",
    "            tags = 'span'\r\n",
    "        else:\r\n",
    "            doc_paragraphs = font_doc_paragraphs\r\n",
    "            tags = 'font'\r\n",
    "\r\n",
    "        #For every word in the range of the length of the list of \"primary_word list\" run the code underneath\r\n",
    "        for p_word in range(len(primary_wordlist)):\r\n",
    "\r\n",
    "            # For every line in the range of the length of the \"doc_paragraphs\" run the code underneath\r\n",
    "            for j in range(len(doc_paragraphs)):\r\n",
    "\r\n",
    "                # If an instance of a primary word is somewhere in the \"item_1a_paragrpahs list\", then run the code underneath\r\n",
    "                if primary_wordlist[p_word] in doc_paragraphs[j].get_text():\r\n",
    "\r\n",
    "                    found = str(doc_paragraphs[j].get_text())\r\n",
    "\r\n",
    "                    # before_found is the instance before the position the primary word was found in, so in that case -1 the index\r\n",
    "                    try:\r\n",
    "                        before_found = str(doc_paragraphs[j-1].get_text())\r\n",
    "                        while len(before_found) <= 2:\r\n",
    "                            foundcount +=1\r\n",
    "                            before_found = str(doc_paragraphs[j-foundcount].get_text())\r\n",
    "                    except:\r\n",
    "                        before_found = 'None'\r\n",
    "\r\n",
    "                    # after_found is the instance after the position the primary word was found in, so in that case  +1 the index\r\n",
    "                    try:\r\n",
    "                        after_found = str(doc_paragraphs[j+1].get_text())\r\n",
    "                    # If the length of the after found paragrpah is less than or equal to 2 characters it is most likely a space, number, or bullet point. In that case, skip it by incrementint\r\n",
    "                        while len(after_found) <= 2:\r\n",
    "                            foundcount +=1\r\n",
    "                            after_found = str(doc_paragraphs[j+foundcount].get_text())\r\n",
    "                    except:\r\n",
    "                        after_found = 'None'\r\n",
    "\r\n",
    "                    #For every secondary word in the secondary word list, run the code below\r\n",
    "                    for s_word in range(len(secondary_wordlist)):  \r\n",
    "\r\n",
    "                        if secondary_wordlist[s_word] in found:\r\n",
    "                            '''print(\"CIK: \", current_cik[doc])\r\n",
    "                            print('PRIMARY WORD: ', primary_wordlist[p_word])\r\n",
    "                            print('SECONDARY WORD:', secondary_wordlist[s_word])\r\n",
    "                            print('ENTIRE DOCUMENT', '\\n\\n')\r\n",
    "\r\n",
    "                            print(\"\\tbefore: \",before_found, '\\n\\n')\r\n",
    "                            print(\"\\tmatch: \",found, '\\n\\n')\r\n",
    "                            print(\"----------------------\")'''\r\n",
    "\r\n",
    "                            found_dict = {\r\n",
    "                                    \"CIK\" : current_cik[doc],\r\n",
    "                                    \"Company Name\" : getCompanyName(documents[doc]),\r\n",
    "                                    \"Item\": 'Entire Document',\r\n",
    "                                    \"Primary Word\" : primary_wordlist[p_word],\r\n",
    "                                    \"Secondary Word\" : secondary_wordlist[s_word],\r\n",
    "                                    \"Tag\": tags,\r\n",
    "                                    \"match\" : found\r\n",
    "                                }\r\n",
    "                            print('added to database')\r\n",
    "                            '''ids = collection.insert_one(found_dict)\r\n",
    "                            print('added', ids)'''\r\n",
    "\r\n",
    "                        elif secondary_wordlist[s_word] in after_found and secondary_wordlist[s_word] in before_found:\r\n",
    "\r\n",
    "                            found_dict = {\r\n",
    "                                \"CIK\" : current_cik[doc],\r\n",
    "                                \"Company Name\" : getCompanyName(documents[doc]),\r\n",
    "                                \"Item\": 'Entire Document',\r\n",
    "                                \"Primary Word\" : primary_wordlist[p_word],\r\n",
    "                                \"Secondary Word\" : secondary_wordlist[s_word],\r\n",
    "                                \"Tag\": tags,\r\n",
    "                                \"before\": before_found,\r\n",
    "                                \"match\" : found,\r\n",
    "                                \"after\" : after_found\r\n",
    "                            } \r\n",
    "                            print('added to database')\r\n",
    "                            '''ids = collection.insert_one(found_dict)\r\n",
    "                            print('added', ids)'''\r\n",
    "\r\n",
    "                        # If there is a secondary word in the before paragraph, then run the code underneath\r\n",
    "                        elif secondary_wordlist[s_word] in before_found:\r\n",
    "\r\n",
    "                            found_dict = {\r\n",
    "                                    \"CIK\" : current_cik[doc],\r\n",
    "                                    \"Company Name\" : getCompanyName(documents[doc]),\r\n",
    "                                    \"Item\": 'Entire Document',\r\n",
    "                                    \"Primary Word\" : primary_wordlist[p_word],\r\n",
    "                                    \"Secondary Word\" : secondary_wordlist[s_word],\r\n",
    "                                    \"Tag\": tags,\r\n",
    "                                    \"before\": before_found,\r\n",
    "                                    \"match\" : found\r\n",
    "                                }\r\n",
    "                            print('added to database')\r\n",
    "                            '''ids = collection.insert_one(found_dict)\r\n",
    "                            print('added', ids)'''\r\n",
    "\r\n",
    "                        # Else if there is a secondary word in the after found paragraph, then run the code underneath\r\n",
    "                        elif secondary_wordlist[s_word] in after_found:\r\n",
    "\r\n",
    "                            found_dict = {\"CIK\" : current_cik[doc],\r\n",
    "                                    \"Company Name\" : getCompanyName(documents[doc]),\r\n",
    "                                    \"Item\": 'Entire Document',\r\n",
    "                                    \"Primary Word\" : primary_wordlist[p_word],\r\n",
    "                                    \"Secondary Word\" : secondary_wordlist[s_word],\r\n",
    "                                    \"Tag\": tags,\r\n",
    "                                    \"match\" : found,\r\n",
    "                                    \"after\" : after_found}\r\n",
    "                            print('added to database')\r\n",
    "                            '''ids = collection.insert_one(found_dict)\r\n",
    "                            print('added', ids)'''\r\n",
    "\r\n",
    "                        else:\r\n",
    "                            pass\r\n",
    "                else:\r\n",
    "                    continue\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connected successfully!!!\n",
      "Checking document sec-edgar-filings\\0000001750\\10-K\\0001104659-20-085310\\full-submission.txt\n",
      "Checking number 0 out of 3634\n",
      "Checking document sec-edgar-filings\\0000001800\\10-K\\0001104659-21-025751\\full-submission.txt\n",
      "Checking number 1 out of 3634\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-26d5d77fe2ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Checking number'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'out of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m#Add all of the paragraphs to the item_1a_paragrpahs list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mdoc_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_10k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m#This block of code finds the tag with the most amount of information inside of it and makes it the primary tag for finding things\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\builder\\_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\builder\\_lxml.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getNsTag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mnsprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prefix_for_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prefix_for_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \"\"\"\n\u001b[0;32m    695\u001b[0m         \u001b[1;31m# print(\"Start tag %s: %s\" % (name, attrs))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         if (self.parse_only and len(self.tagStack) <= 1\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mendData\u001b[1;34m(self, containerClass)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[0moccurs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \"\"\"\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mcontainerClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainerClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mstring_container\u001b[1;34m(self, base_class)\u001b[0m\n\u001b[0;32m    476\u001b[0m         )\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mstring_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_class\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mNavigableString\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "87b2800b0c1b1ef7516301f78dddd1d50cc2355215b22447e1facc53db262490"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}